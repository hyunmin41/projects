{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"~\\\\data1.csv\", header=0,engine='python') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[0:117]\n",
    "df = df[[\"날짜\",\"정책\",\"정책지수\",\"누적정책지수\",\"서울\",\"용산구\",\"광진구\",\"서대문구\",\"영등포구\",\"서초구\",\"소비자물가지수\",\"한국은행기준금리\",\"원달러환율\",\"가계대출\",\"서울시부동산심리지수\",\"서울실거래지수\",\"도심권실거래지수\",\"동북권실거래지수\",\"서북권실거래지수\",\"서남권실거래지수\",\"동남권실거래지수\"]]\n",
    "df.columns = [\"date\",\"1\",\"PI\",\"PI2\",\"Seoul\",\"Yongsan-gu\",\"Gwangjin-gu\",\"Seodaemun-gu\",\"Yeongdeungpo-gu\",\"Seocho-gu\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\",\"SI\",\"CI\",\"NEI\",\"NWI\",\"SWI\",\"SEI\"]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df[[\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "\n",
    "whole1 = df[[\"Seoul\",\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "\n",
    "whole2 = df[[\"Yongsan-gu\",\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "whole3 = df[[\"Gwangjin-gu\",\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "whole4 = df[[\"Seodaemun-gu\",\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "whole5 = df[[\"Yeongdeungpo-gu\",\"PI\",\"CPI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "whole6 = df[[\"Seocho-gu\",\"CPI\",\"PI\",\"BR\",\"ER\",\"HL\",\"EI\"]]\n",
    "\n",
    "label = df[[\"Seoul\",\"Yongsan-gu\",\"Gwangjin-gu\",\"Seodaemun-gu\",\"Yeongdeungpo-gu\",\"Seocho-gu\"]]\n",
    "\n",
    "label1 = df[[\"Seoul\"]]\n",
    "label2 = df[[\"Yongsan-gu\"]]\n",
    "label3 = df[[\"Gwangjin-gu\"]]\n",
    "label4 = df[[\"Seodaemun-gu\"]]\n",
    "label5 = df[[\"Yeongdeungpo-gu\"]]\n",
    "label6 = df[[\"Seocho-gu\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Yongsan-gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "xdata = scaler.fit_transform(feature)\n",
    "ydata = scaler.fit_transform(label2)\n",
    "wholedata=scaler.fit_transform(whole2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back = 1\n",
    "X_whole, Y_whole = [], []\n",
    "for i in range(len(wholedata)-step_back - 1):\n",
    "    a = wholedata[i:(i+step_back), 1:]\n",
    "    X_whole.append(a)\n",
    "    Y_whole.append(wholedata[i + step_back, 0])\n",
    "X_whole = np.array(X_whole); Y_whole = np.array(Y_whole)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "import keras.backend as K \n",
    "import tensorflow as tf\n",
    "\n",
    "kfold=KFold(10)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_whole, Y_whole):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_whole, Y_whole, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "    X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "    \n",
    "    output_size=7\n",
    "    activ_func=\"relu\"\n",
    "    dropout=0.25\n",
    "    loss=\"mean_squared_error\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units=30, return_sequences=True))\n",
    "    model.add(Dense(units=output_size,activation=activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam',metrics =[\"mse\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=24, verbose=0,shuffle=False)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xdata)*0.9)+4\n",
    "x_train_dataset, x_test_dataset = xdata[0:train_size,:], xdata[train_size:,:]\n",
    "y_train_dataset, y_test_dataset = ydata[0:train_size], ydata[train_size:]\n",
    "\n",
    "# Window -> X timestep back\n",
    "step_back= 1\n",
    "X_train, Y_train = [], []\n",
    "for i in range(len(x_train_dataset)-step_back - 1):\n",
    "    a = x_train_dataset[i:(i+step_back), :]\n",
    "    X_train.append(a)\n",
    "    Y_train.append(y_train_dataset[i + step_back, 0])\n",
    "X_train = np.array(X_train); Y_train = np.array(Y_train)\n",
    "    \n",
    "X_test, Y_test = [], []\n",
    "for i in range(len(x_test_dataset)-step_back - 1):\n",
    "    a = x_test_dataset[i:(i+step_back), :]\n",
    "    X_test.append(a)\n",
    "    Y_test.append(y_test_dataset[i + step_back, 0])\n",
    "X_test = np.array(X_test); Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(Y_train.shape);             \n",
    "print(X_test.shape); print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "    \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "Y_test  = np.reshape(Y_test, (Y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GRU network in keras\n",
    "\n",
    "output_size=7\n",
    "activ_func=\"relu\"\n",
    "dropout=0.25\n",
    "loss=\"mean_squared_error\" \n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(Dense(10))\n",
    "model_gru.add(Dropout(0.25))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(Dense(units=output_size, activation=\"relu\"))\n",
    "\n",
    "model_gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = model_gru.fit(X_train, Y_train, epochs=50, batch_size=24, validation_data=(X_test, Y_test), shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance\n",
    "trainScore = model_gru.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the skill of the Trained model\n",
    "testPredict  = model_gru.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[]\n",
    "for i in range(0,testPredict.shape[0]):\n",
    "    result1.append(testPredict[i][0])\n",
    "    i=+1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "testPredict1 = scaler.inverse_transform(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred=[]\n",
    "for i in range(0,testPredict1.shape[0]):\n",
    "    result_pred.append(testPredict1[i][0])\n",
    "    i=+1\n",
    "\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=[]\n",
    "for i in range(0,len(result1)):\n",
    "    result11.append(result1[i][0])\n",
    "    i=+1\n",
    "result11=np.reshape(result11,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "math.sqrt(sum((result11-Y_test)**2)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "plt.scatter(result11,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "#plt.figure(figsize=(10,6))\n",
    "plt.plot(result_pred)\n",
    "plt.plot(label2[-6:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gwangjin-gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "xdata = scaler.fit_transform(feature)\n",
    "ydata = scaler.fit_transform(label3)\n",
    "wholedata=scaler.fit_transform(whole3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back = 1\n",
    "X_whole, Y_whole = [], []\n",
    "for i in range(len(wholedata)-step_back - 1):\n",
    "    a = wholedata[i:(i+step_back), 1:]\n",
    "    X_whole.append(a)\n",
    "    Y_whole.append(wholedata[i + step_back, 0])\n",
    "X_whole = np.array(X_whole); Y_whole = np.array(Y_whole)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "import keras.backend as K \n",
    "import tensorflow as tf\n",
    "\n",
    "kfold=KFold(10)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_whole, Y_whole):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_whole, Y_whole, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "    X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "    \n",
    "    output_size=7\n",
    "    activ_func=\"relu\"\n",
    "    dropout=0.25\n",
    "    loss=\"mean_squared_error\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units=30, return_sequences=True))\n",
    "    model.add(Dense(units=output_size,activation=activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam',metrics =[\"mse\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=70, batch_size=12, verbose=0,shuffle=False)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xdata)*0.9)+4\n",
    "x_train_dataset, x_test_dataset = xdata[0:train_size,:], xdata[train_size:,:]\n",
    "y_train_dataset, y_test_dataset = ydata[0:train_size], ydata[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back= 1\n",
    "X_train, Y_train = [], []\n",
    "for i in range(len(x_train_dataset)-step_back - 1):\n",
    "    a = x_train_dataset[i:(i+step_back), :]\n",
    "    X_train.append(a)\n",
    "    Y_train.append(y_train_dataset[i + step_back, 0])\n",
    "X_train = np.array(X_train); Y_train = np.array(Y_train)\n",
    "    \n",
    "X_test, Y_test = [], []\n",
    "for i in range(len(x_test_dataset)-step_back - 1):\n",
    "    a = x_test_dataset[i:(i+step_back), :]\n",
    "    X_test.append(a)\n",
    "    Y_test.append(y_test_dataset[i + step_back, 0])\n",
    "X_test = np.array(X_test); Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(Y_train.shape);             \n",
    "print(X_test.shape); print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "    \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "Y_test  = np.reshape(Y_test, (Y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GRU network in keras\n",
    "\n",
    "output_size=7\n",
    "activ_func=\"relu\"\n",
    "dropout=0.25\n",
    "loss=\"mean_squared_error\" \n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(Dense(10))\n",
    "model_gru.add(Dropout(0.25))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(Dense(units=output_size, activation=\"relu\"))\n",
    "\n",
    "model_gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = model_gru.fit(X_train, Y_train, epochs=70, batch_size=12, validation_data=(X_test, Y_test), shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance\n",
    "trainScore = model_gru.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the skill of the Trained model\n",
    "testPredict  = model_gru.predict(X_test)\n",
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[]\n",
    "for i in range(0,testPredict.shape[0]):\n",
    "    result1.append(testPredict[i][0])\n",
    "    i=+1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "testPredict1 = scaler.inverse_transform(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred=[]\n",
    "for i in range(0,testPredict1.shape[0]):\n",
    "    result_pred.append(testPredict1[i][0])\n",
    "    i=+1\n",
    "\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=[]\n",
    "for i in range(0,len(result1)):\n",
    "    result11.append(result1[i][0])\n",
    "    i=+1\n",
    "result11=np.reshape(result11,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "math.sqrt(sum((result11-Y_test)**2)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "plt.scatter(result11,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "#plt.figure(figsize=(10,6))\n",
    "plt.plot(result_pred)\n",
    "plt.plot(label3[-6:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Seodaemun-gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "xdata = scaler.fit_transform(feature)\n",
    "ydata = scaler.fit_transform(label4)\n",
    "wholedata=scaler.fit_transform(whole4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back = 1\n",
    "X_whole, Y_whole = [], []\n",
    "for i in range(len(wholedata)-step_back - 1):\n",
    "    a = wholedata[i:(i+step_back), 1:]\n",
    "    X_whole.append(a)\n",
    "    Y_whole.append(wholedata[i + step_back, 0])\n",
    "X_whole = np.array(X_whole); Y_whole = np.array(Y_whole)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "import keras.backend as K \n",
    "import tensorflow as tf\n",
    "\n",
    "kfold=KFold(10)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_whole, Y_whole):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_whole, Y_whole, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "    X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "    \n",
    "    output_size=7\n",
    "    activ_func=\"relu\"\n",
    "    dropout=0.25\n",
    "    loss=\"mean_squared_error\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units=30, return_sequences=True))\n",
    "    model.add(Dense(units=output_size,activation=activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam',metrics =[\"mse\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=24, verbose=0,shuffle=False)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xdata)*0.9)+4\n",
    "x_train_dataset, x_test_dataset = xdata[0:train_size,:], xdata[train_size:,:]\n",
    "y_train_dataset, y_test_dataset = ydata[0:train_size], ydata[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back= 1\n",
    "X_train, Y_train = [], []\n",
    "for i in range(len(x_train_dataset)-step_back - 1):\n",
    "    a = x_train_dataset[i:(i+step_back), :]\n",
    "    X_train.append(a)\n",
    "    Y_train.append(y_train_dataset[i + step_back, 0])\n",
    "X_train = np.array(X_train); Y_train = np.array(Y_train)\n",
    "    \n",
    "X_test, Y_test = [], []\n",
    "for i in range(len(x_test_dataset)-step_back - 1):\n",
    "    a = x_test_dataset[i:(i+step_back), :]\n",
    "    X_test.append(a)\n",
    "    Y_test.append(y_test_dataset[i + step_back, 0])\n",
    "X_test = np.array(X_test); Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(Y_train.shape);             \n",
    "print(X_test.shape); print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "    \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "Y_test  = np.reshape(Y_test, (Y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GRU network in keras\n",
    "\n",
    "output_size=7\n",
    "activ_func=\"relu\"\n",
    "dropout=0.25\n",
    "loss=\"mean_squared_error\" \n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(Dense(10))\n",
    "model_gru.add(Dropout(0.25))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(Dense(units=output_size, activation=\"relu\"))\n",
    "\n",
    "model_gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = model_gru.fit(X_train, Y_train, epochs=50, batch_size=24, validation_data=(X_test, Y_test), shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance\n",
    "trainScore = model_gru.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the skill of the Trained model\n",
    "testPredict  = model_gru.predict(X_test)\n",
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[]\n",
    "for i in range(0,testPredict.shape[0]):\n",
    "    result1.append(testPredict[i][0])\n",
    "    i=+1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "testPredict1 = scaler.inverse_transform(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred=[]\n",
    "for i in range(0,testPredict1.shape[0]):\n",
    "    result_pred.append(testPredict1[i][0])\n",
    "    i=+1\n",
    "\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=[]\n",
    "for i in range(0,len(result1)):\n",
    "    result11.append(result1[i][0])\n",
    "    i=+1\n",
    "result11=np.reshape(result11,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "math.sqrt(sum((result11-Y_test)**2)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "plt.scatter(result11,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "#plt.figure(figsize=(10,6))\n",
    "plt.plot(result_pred)\n",
    "plt.plot(label4[-6:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Yeongdeungpo-gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "xdata = scaler.fit_transform(feature)\n",
    "ydata = scaler.fit_transform(label5)\n",
    "wholedata=scaler.fit_transform(whole5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back = 1\n",
    "X_whole, Y_whole = [], []\n",
    "for i in range(len(wholedata)-step_back - 1):\n",
    "    a = wholedata[i:(i+step_back), 1:]\n",
    "    X_whole.append(a)\n",
    "    Y_whole.append(wholedata[i + step_back, 0])\n",
    "X_whole = np.array(X_whole); Y_whole = np.array(Y_whole)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "import keras.backend as K \n",
    "import tensorflow as tf\n",
    "\n",
    "kfold=KFold(10)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_whole, Y_whole):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_whole, Y_whole, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "    X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "    \n",
    "    output_size=7\n",
    "    activ_func=\"relu\"\n",
    "    dropout=0.25\n",
    "    loss=\"mean_squared_error\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units=30, return_sequences=True))\n",
    "    model.add(Dense(units=output_size,activation=activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam',metrics =[\"mse\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=70, batch_size=12, verbose=0,shuffle=False)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xdata)*0.9)+4\n",
    "x_train_dataset, x_test_dataset = xdata[0:train_size,:], xdata[train_size:,:]\n",
    "y_train_dataset, y_test_dataset = ydata[0:train_size], ydata[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back= 1\n",
    "X_train, Y_train = [], []\n",
    "for i in range(len(x_train_dataset)-step_back - 1):\n",
    "    a = x_train_dataset[i:(i+step_back), :]\n",
    "    X_train.append(a)\n",
    "    Y_train.append(y_train_dataset[i + step_back, 0])\n",
    "X_train = np.array(X_train); Y_train = np.array(Y_train)\n",
    "    \n",
    "X_test, Y_test = [], []\n",
    "for i in range(len(x_test_dataset)-step_back - 1):\n",
    "    a = x_test_dataset[i:(i+step_back), :]\n",
    "    X_test.append(a)\n",
    "    Y_test.append(y_test_dataset[i + step_back, 0])\n",
    "X_test = np.array(X_test); Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(Y_train.shape);             \n",
    "print(X_test.shape); print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "    \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], step_back,6))\n",
    "X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "Y_test  = np.reshape(Y_test, (Y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GRU network in keras\n",
    "\n",
    "output_size=7\n",
    "activ_func=\"relu\"\n",
    "dropout=0.25\n",
    "loss=\"mean_squared_error\" \n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(Dense(5))\n",
    "model_gru.add(Dropout(0.25))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(Dense(units=output_size, activation=\"relu\"))\n",
    "\n",
    "model_gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = model_gru.fit(X_train, Y_train, epochs=70, batch_size=12, validation_data=(X_test, Y_test), shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance\n",
    "trainScore = model_gru.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the skill of the Trained model\n",
    "testPredict  = model_gru.predict(X_test)\n",
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[]\n",
    "for i in range(0,testPredict.shape[0]):\n",
    "    result1.append(testPredict[i][0])\n",
    "    i=+1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "testPredict1 = scaler.inverse_transform(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred=[]\n",
    "for i in range(0,testPredict1.shape[0]):\n",
    "    result_pred.append(testPredict1[i][0])\n",
    "    i=+1\n",
    "\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=[]\n",
    "for i in range(0,len(result1)):\n",
    "    result11.append(result1[i][0])\n",
    "    i=+1\n",
    "result11=np.reshape(result11,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "math.sqrt(sum((result11-Y_test)**2)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "plt.scatter(result11,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "#plt.figure(figsize=(10,6))\n",
    "plt.plot(result_pred)\n",
    "plt.plot(label5[-6:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Seocho-gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "xdata = scaler.fit_transform(feature)\n",
    "ydata = scaler.fit_transform(label6)\n",
    "wholedata=scaler.fit_transform(whole6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back = 1\n",
    "X_whole, Y_whole = [], []\n",
    "for i in range(len(wholedata)-step_back - 1):\n",
    "    a = wholedata[i:(i+step_back), 1:]\n",
    "    X_whole.append(a)\n",
    "    Y_whole.append(wholedata[i + step_back, 0])\n",
    "X_whole = np.array(X_whole); Y_whole = np.array(Y_whole)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "import keras.backend as K \n",
    "import tensorflow as tf\n",
    "\n",
    "kfold=KFold(10)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_whole, Y_whole):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_whole, Y_whole, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "    X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "    \n",
    "    output_size=7\n",
    "    activ_func=\"relu\"\n",
    "    dropout=0.25\n",
    "    loss=\"mean_squared_error\" \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(GRU(units=30, return_sequences=True))\n",
    "    model.add(Dense(units=output_size,activation=activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam',metrics =[\"mse\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=70, batch_size=12, verbose=0,shuffle=False)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(xdata)*0.9)+4\n",
    "x_train_dataset, x_test_dataset = xdata[0:train_size,:], xdata[train_size:,:]\n",
    "y_train_dataset, y_test_dataset = ydata[0:train_size], ydata[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window -> X timestep back\n",
    "step_back= 1\n",
    "X_train, Y_train = [], []\n",
    "for i in range(len(x_train_dataset)-step_back - 1):\n",
    "    a = x_train_dataset[i:(i+step_back), :]\n",
    "    X_train.append(a)\n",
    "    Y_train.append(y_train_dataset[i + step_back, 0])\n",
    "X_train = np.array(X_train); Y_train = np.array(Y_train)\n",
    "    \n",
    "X_test, Y_test = [], []\n",
    "for i in range(len(x_test_dataset)-step_back - 1):\n",
    "    a = x_test_dataset[i:(i+step_back), :]\n",
    "    X_test.append(a)\n",
    "    Y_test.append(y_test_dataset[i + step_back, 0])\n",
    "X_test = np.array(X_test); Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(Y_train.shape);             \n",
    "print(X_test.shape); print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "    \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], step_back, 6))\n",
    "X_test  = np.reshape(X_test, (X_test.shape[0], step_back, 6))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "Y_test  = np.reshape(Y_test, (Y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GRU network in keras\n",
    "\n",
    "output_size=7\n",
    "activ_func=\"relu\"\n",
    "dropout=0.25\n",
    "loss=\"mean_squared_error\" \n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(75, return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(Dense(5))\n",
    "model_gru.add(Dropout(0.25))\n",
    "model_gru.add(GRU(units=30, return_sequences=True))\n",
    "model_gru.add(Dense(units=output_size, activation=\"relu\"))\n",
    "\n",
    "model_gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = model_gru.fit(X_train, Y_train, epochs=70, batch_size=12, validation_data=(X_test, Y_test), shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance\n",
    "trainScore = model_gru.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the skill of the Trained model\n",
    "testPredict  = model_gru.predict(X_test)\n",
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[]\n",
    "for i in range(0,testPredict.shape[0]):\n",
    "    result1.append(testPredict[i][0])\n",
    "    i=+1\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "testPredict1 = scaler.inverse_transform(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred=[]\n",
    "for i in range(0,testPredict1.shape[0]):\n",
    "    result_pred.append(testPredict1[i][0])\n",
    "    i=+1\n",
    "\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11=[]\n",
    "for i in range(0,len(result1)):\n",
    "    result11.append(result1[i][0])\n",
    "    i=+1\n",
    "result11=np.reshape(result11,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "math.sqrt(sum((result11-Y_test)**2)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "plt.scatter(result11,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "#plt.figure(figsize=(10,6))\n",
    "plt.plot(result_pred)\n",
    "plt.plot(label6[-6:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d951a4fb713309e6a15ac834ff0fb502c06e5ab8683a64badeae54cb1002e2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
